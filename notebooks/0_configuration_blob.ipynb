{"cells":[{"cell_type":"markdown","source":["# Environment setup\nIn this notebook, you will quickly set up the Databricks environment for use with Azure Data Lake Storage Gen2 (ADLS Gen2).\n\n### Attach notebook to you cluster\nBefore executing any cells in your notebook, you need to attach it to your cluster. In the notebook's toolbar, select the drop down arrow next to Detached, and then select your cluster under attach to.\n\nRun the next cell to initialize your filesystem and mount it with DBFS."],"metadata":{}},{"cell_type":"markdown","source":["## Connect to Azure Machine Learning Workspace"],"metadata":{}},{"cell_type":"code","source":["import azureml.core\n\nfrom azureml.core import Workspace, Dataset\nfrom azureml.core.authentication import ServicePrincipalAuthentication\nfrom azureml.core.datastore import Datastore\n\nservice_principal_id = dbutils.secrets.get(keyVaultScope, \"databricks-aml-demo-sp-client-id\")\nservice_principal_password = dbutils.secrets.get(keyVaultScope, \"databricks-aml-demo-sp-client-key\")\ntenant_id = dbutils.secrets.get(keyVaultScope, \"azure-tenant-id\")\n\n\n# PRODUCTION AML WORKSPACE\nworkspace_name = \"amls-databricks\"\nsubscription_id = dbutils.secrets.get(keyVaultScope, \"azure-subscription-id\")\nresource_group = \"jp-databricks\"\n\n\nsvc_pr = ServicePrincipalAuthentication(\n    service_principal_id=service_principal_id,\n    service_principal_password=service_principal_password,\n    tenant_id=tenant_id\n    )\n\nws = Workspace(workspace_name=workspace_name,\n               subscription_id=subscription_id,\n               resource_group=resource_group,\n               auth=svc_pr)\n\nprint(\"Found workspace {} at location {}\".format(ws.name, ws.location))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Found workspace amls-databricks at location centralus\n</div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["## Mount Azure Blob Storage, copy sample dataset and register in Azure Machine Learning"],"metadata":{}},{"cell_type":"code","source":["# Get default datastore and upload dataset\ndatastore = ws.get_default_datastore()\n\n# Variable declarations. These will be accessible by any calling notebook.\nkeyVaultScope = \"databricks-aml-demo\"\nblobaccountname = dbutils.secrets.get(keyVaultScope, \"blob-accountname\")\n\n# Mount the Azure Blob Storage.\nif not any(mount.mountPoint == f\"/mnt/{datastore.container_name}\" for mount in dbutils.fs.mounts()):\n  dbutils.fs.mount(\n    source = f\"wasbs://{datastore.container_name}@{blobaccountname}.blob.core.windows.net\", \n    mount_point = f\"/mnt/{datastore.container_name}\",\n    extra_configs = {f\"fs.azure.account.key.{blobaccountname}.blob.core.windows.net\":dbutils.secrets.get(keyVaultScope, key = \"blob-account-key\")})"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Copy data from dbfs to temp storage for upload and registration in AML\ndbutils.fs.cp ('dbfs:/databricks-datasets/samples/population-vs-price/data_geo.csv', f'/mnt/{datastore.container_name}/population-vs-price/data_geo.csv')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[35]: True</div>"]}}],"execution_count":6},{"cell_type":"code","source":["dataset = Dataset.Tabular.from_delimited_files(path = [(datastore, '/population-vs-price/data_geo.csv')], infer_column_types=True)\ndataset.register(workspace=ws, name='data_geo', description='data_geo training data')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[36]: {\n  &#34;source&#34;: [\n    &#34;(&#39;workspaceblobstore&#39;, &#39;population-vs-price/data_geo.csv&#39;)&#34;\n  ],\n  &#34;definition&#34;: [\n    &#34;GetDatastoreFiles&#34;,\n    &#34;ParseDelimited&#34;,\n    &#34;DropColumns&#34;,\n    &#34;SetColumnTypes&#34;\n  ],\n  &#34;registration&#34;: {\n    &#34;id&#34;: &#34;1d357c4d-bc8d-4fdc-a996-bdd06f81d49a&#34;,\n    &#34;name&#34;: &#34;data_geo&#34;,\n    &#34;version&#34;: 1,\n    &#34;description&#34;: &#34;data_geo training data&#34;,\n    &#34;workspace&#34;: &#34;Workspace.create(name=&#39;amls-databricks&#39;, subscription_id=&#39;[REDACTED]&#39;, resource_group=&#39;jp-databricks&#39;)&#34;\n  }\n}</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["## Next\n\nYou have completed the environment setup."],"metadata":{}}],"metadata":{"name":"0_configuration_blob","notebookId":1023156855332456},"nbformat":4,"nbformat_minor":0}
